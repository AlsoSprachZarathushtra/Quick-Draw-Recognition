{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StrokeColor_DenseNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlsoSprachZarathushtra/Quick-Draw-Recognition/blob/master/StrokeColor_DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ioxMYD5fIN0l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Connect Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "QfwNChIWH-gL",
        "colab_type": "code",
        "outputId": "a4b09eda-5ac7-4885-f1de-69dde509f50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bEMTrWPCLoJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import"
      ]
    },
    {
      "metadata": {
        "id": "Bwe8XgfZExAn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import ReLU\n",
        "from tensorflow.keras.layers import Softmax\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.metrics import sparse_top_k_categorical_accuracy\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from ast import literal_eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JUvwhYjZIe-M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters  and  Work-Space Paths"
      ]
    },
    {
      "metadata": {
        "id": "dPOH3112IVQN",
        "colab_type": "code",
        "outputId": "86f12206-d73d-4208-dc73-43e03418a7d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 40\n",
        "STEPS_PER_EPOCH = 1000\n",
        "VALIDATION_STEPS = 100\n",
        "EVALUATE_STEPS = 1700\n",
        "IMAGE_SIZE = 128\n",
        "LINE_SIZE = 4\n",
        "n_class = 340\n",
        "\n",
        "# load path\n",
        "TRAIN_DATA_PATH = 'gdrive/My Drive/QW/Data/Data_10000/All_classes_10000.csv'\n",
        "VALID_DATA_PATH = 'gdrive/My Drive/QW/Data/My_test_data/My_test_data.csv'\n",
        "LABEL_DICT_PATH = 'gdrive/My Drive/QW/Data/labels_dict.npy'\n",
        "\n",
        "# save path\n",
        "CKPT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt'\n",
        "LOSS_PLOT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/loss_plot_densenet.png'\n",
        "ACC_PLOT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/acc_plot_densenet.png'\n",
        "LOG_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/Log_densenet.log'\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bTH2CjZKLbQ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ]
    },
    {
      "metadata": {
        "id": "kCe0hZq3ZBtp",
        "colab_type": "code",
        "outputId": "76e9e53d-eea9-42bc-bd61-372cc413ec6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def generate_data(data, batch_size, choose_recognized):\n",
        "    data = data.sample(frac = 1)\n",
        "    while 1:\n",
        "        \n",
        "#         get columns' values named 'drawing', 'word' and 'recognized'\n",
        "        drawings = data[\"drawing\"].values\n",
        "        drawing_recognized = data[\"recognized\"].values\n",
        "        drawing_class = data[\"word\"].values\n",
        "      \n",
        "#         initialization\n",
        "        cnt = 0\n",
        "        data_X =[]\n",
        "        data_Y =[]\n",
        "        \n",
        "#         generate batch\n",
        "        for i in range(len(drawings)):\n",
        "            if choose_recognized:\n",
        "                if drawing_recognized[i] == 'False':    #Choose according to recognized value\n",
        "                    continue\n",
        "            draw = drawings[i]\n",
        "            label = drawing_class[i]\n",
        "            stroke_vec = literal_eval(draw)\n",
        "            img = np.zeros([256, 256])\n",
        "            x = []\n",
        "            for j in range(len(stroke_vec)): \n",
        "                line = np.array(stroke_vec[j]).T\n",
        "                color = 255-(13*min(j,10))\n",
        "                cv2.polylines(img, [line], False, color, LINE_SIZE)\n",
        "            img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE), interpolation = cv2.INTER_NEAREST)\n",
        "            img = img[:,:, np.newaxis]\n",
        "            x = img\n",
        "            y = labels2nums_dict[label]\n",
        "            data_X.append(x)\n",
        "            data_Y.append(y)\n",
        "            cnt += 1\n",
        "            if cnt==batch_size:        #generate a batch when cnt reaches batch_size \n",
        "                cnt = 0\n",
        "                yield (np.array(data_X), np.array(data_Y))\n",
        "                data_X = []\n",
        "                data_Y = []\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3SIDIfoSR2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Callbacks"
      ]
    },
    {
      "metadata": {
        "id": "fhoAdkcESQiM",
        "colab_type": "code",
        "outputId": "5c681393-7273-4715-adba-3d8d3efc00f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# define a class named LossHitory \n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = {'batch':[], 'epoch':[]}\n",
        "        self.accuracy = {'batch':[], 'epoch':[]}\n",
        "        self.val_loss = {'batch':[], 'epoch':[]}\n",
        "        self.val_acc = {'batch':[], 'epoch':[]}\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses['batch'].append(logs.get('loss'))\n",
        "        self.accuracy['batch'].append(logs.get('acc'))\n",
        "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
        "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.losses['epoch'].append(logs.get('loss'))\n",
        "        self.accuracy['epoch'].append(logs.get('acc'))\n",
        "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
        "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
        "\n",
        "    def loss_plot(self, loss_type, loss_fig_save_path, acc_fig_save_path):\n",
        "        iters = range(len(self.losses[loss_type]))\n",
        "        plt.figure('acc')\n",
        "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
        "        plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
        "        plt.grid(True)\n",
        "        plt.xlabel(loss_type)\n",
        "        plt.ylabel('acc')\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        plt.savefig(acc_fig_save_path)\n",
        "        plt.show()\n",
        "        \n",
        "        \n",
        "        plt.figure('loss')\n",
        "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
        "        plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
        "        plt.grid(True)\n",
        "        plt.xlabel(loss_type)\n",
        "        plt.ylabel('loss')\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        plt.savefig(loss_fig_save_path)\n",
        "        plt.show()\n",
        "        \n",
        "# create a object from LossHistory class\n",
        "History = LossHistory()\n",
        "\n",
        "print(\"finish!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zUBqEb49S7qZ",
        "colab_type": "code",
        "outputId": "d87eb6bd-7793-46e0-ee5b-3d528a77b6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    CKPT_PATH, \n",
        "    verbose = 1, \n",
        "    monitor='val_acc', \n",
        "    mode = 'max', \n",
        "    save_best_only=True)\n",
        "\n",
        "print(\"finish!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UAb_4FpSQo-j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3,\n",
        "                      min_delta=0.005, mode='max', cooldown=3, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdHOp_LLskQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "csv_logger = CSVLogger(LOG_PATH, separator=',', append=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bwRxaI2QTibU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ]
    },
    {
      "metadata": {
        "id": "aj041zzZTwrF",
        "colab_type": "code",
        "outputId": "f9152e7b-b7ac-4de8-f043-c531646d4551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# load train data and valid data\n",
        "#  labels_dict and data path\n",
        "\n",
        "# labels convert into nums\n",
        "labels_dict = np.load(LABEL_DICT_PATH)\n",
        "labels2nums_dict = {v: k for k, v in enumerate(labels_dict)}\n",
        "\n",
        "# read csv \n",
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "valid_data = pd.read_csv(VALID_DATA_PATH)\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D_sA1QMzUysO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "-DXg_7LEU1Ap",
        "colab_type": "code",
        "outputId": "af6af454-0faa-4cc1-87e3-5ee1e4e74627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16705
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "MODEL = tf.keras.applications.DenseNet121(\n",
        "        input_shape=(IMAGE_SIZE,IMAGE_SIZE,1),\n",
        "        include_top=True,\n",
        "        weights=None,\n",
        "        classes=n_class\n",
        "        )\n",
        "\n",
        "MODEL.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 134, 134, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 64, 64, 64)   3136        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalizationV1) (None, 64, 64, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 64, 64, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 32, 32, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 32, 32, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 32, 32, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 32, 32, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 32, 32, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 32, 32, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 32, 32, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 32, 32, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 32, 32, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 32, 32, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 32, 32, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 32, 32, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 32, 32, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 32, 32, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 32, 32, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 32, 32, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 32, 32, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 32, 32, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 32, 32, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 32, 32, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 32, 32, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 32, 32, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 32, 32, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 32, 32, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalizationV1) (None, 32, 32, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 32, 32, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 32, 32, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 16, 16, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 16, 16, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 16, 16, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 16, 16, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 16, 16, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 16, 16, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 16, 16, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 16, 16, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 16, 16, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 16, 16, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 16, 16, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 16, 16, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 16, 16, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 16, 16, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 16, 16, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 16, 16, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 16, 16, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 16, 16, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 16, 16, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 16, 16, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 16, 16, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 16, 16, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 16, 16, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 16, 16, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 16, 16, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 16, 16, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 16, 16, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 16, 16, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 16, 16, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 16, 16, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 16, 16, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 16, 16, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 16, 16, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 16, 16, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 16, 16, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 16, 16, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 16, 16, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 16, 16, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 16, 16, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 16, 16, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalizationV1) (None, 16, 16, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 16, 16, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 16, 16, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 8, 8, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 8, 8, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 8, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 8, 8, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 8, 8, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 8, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 8, 8, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 8, 8, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 8, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 8, 8, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 8, 8, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 8, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 8, 8, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 8, 8, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 8, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 8, 8, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 8, 8, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 8, 8, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 8, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 8, 8, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 8, 8, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 8, 8, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 8, 8, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 8, 8, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 8, 8, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 8, 8, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 8, 8, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 8, 8, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 8, 8, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 8, 8, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 8, 8, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 8, 8, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 8, 8, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 8, 8, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 8, 8, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 8, 8, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 8, 8, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 8, 8, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 8, 8, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 8, 8, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 8, 8, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 8, 8, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 8, 8, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 8, 8, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 8, 8, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 8, 8, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 8, 8, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 8, 8, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 8, 8, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 8, 8, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 8, 8, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 8, 8, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 8, 8, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 8, 8, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 8, 8, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 8, 8, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 8, 8, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 8, 8, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 8, 8, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 8, 8, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 8, 8, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 8, 8, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 8, 8, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 8, 8, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 8, 8, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 8, 8, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 8, 8, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 8, 8, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 8, 8, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalizationV1) (None, 8, 8, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 8, 8, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 8, 8, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 4, 4, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 4, 4, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 4, 4, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 4, 4, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 4, 4, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 4, 4, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 4, 4, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 4, 4, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 4, 4, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 4, 4, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 4, 4, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 4, 4, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 4, 4, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 4, 4, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 4, 4, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 4, 4, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 4, 4, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 4, 4, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 4, 4, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 4, 4, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 4, 4, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 4, 4, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 4, 4, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 4, 4, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 4, 4, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 4, 4, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 4, 4, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 4, 4, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 4, 4, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 4, 4, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 4, 4, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 4, 4, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 4, 4, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 4, 4, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalizationV1)       (None, 4, 4, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 4, 4, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "fc1000 (Dense)                  (None, 340)          348500      avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,379,732\n",
            "Trainable params: 7,296,084\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "02zm3e7qU87T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Complie"
      ]
    },
    {
      "metadata": {
        "id": "Rtz3F1UAU_RW",
        "colab_type": "code",
        "outputId": "089ca2b9-c25b-4285-ace1-2703fb5a34c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "cell_type": "code",
      "source": [
        "model = MODEL\n",
        "\n",
        "TPU_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "            tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "TPU_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                  optimizer=tf.train.AdamOptimizer(learning_rate=1e-5),\n",
        "                  metrics=['accuracy'])\n",
        "TPU_model.load_weights(CKPT_PATH)\n",
        "print('finish')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.10.98.18:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11422646713076668804)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 10110685780123374831)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 162110997482080377)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18215615646825693293)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16007561700920417646)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11162713970302912307)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 3269261611291188145)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8096694146553499938)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3933854027872841076)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16119630269786143645)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9414942764022770418)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hOj3QaVNVm-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "5Kl8pgH8Vope",
        "colab_type": "code",
        "outputId": "fb0c8e2d-45ba-4250-f79a-f2c0a58ff6f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3053
        }
      },
      "cell_type": "code",
      "source": [
        "print('start training')\n",
        "# callbacks = [History, cp_callback]\n",
        "\n",
        "history = TPU_model.fit_generator(generate_data(train_data, BATCH_SIZE, True),\n",
        "                              steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                              epochs = EPOCHS,\n",
        "                              validation_data = generate_data(valid_data, BATCH_SIZE, False) ,\n",
        "                              validation_steps = VALIDATION_STEPS,\n",
        "                              verbose = 1,\n",
        "                              initial_epoch = 20,\n",
        "                              callbacks = [History,cp_callback,csv_logger]\n",
        "                             )\n",
        "print(\"finish training\")\n",
        "\n",
        "History.loss_plot('epoch', LOSS_PLOT_PATH, ACC_PLOT_PATH)\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training\n",
            "Epoch 21/40\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 128, 128, 1), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 1), dtype=tf.int32, name='fc1000_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 102.12913990020752 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.1093 - acc: 0.7221INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 128, 128, 1), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 1), dtype=tf.int32, name='fc1000_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 68.87522578239441 secs\n",
            "100/100 [==============================] - 89s 894ms/step - loss: 1.0443 - acc: 0.7356\n",
            "\n",
            "Epoch 00021: val_acc improved from -inf to 0.73562, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 1479s 1s/step - loss: 1.1092 - acc: 0.7221 - val_loss: 1.0443 - val_acc: 0.7356\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 1.0093 - acc: 0.7436\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.73562 to 0.74359, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 660s 660ms/step - loss: 1.0767 - acc: 0.7303 - val_loss: 1.0093 - val_acc: 0.7436\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 1.0279 - acc: 0.7427\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.74359\n",
            "1000/1000 [==============================] - 636s 636ms/step - loss: 1.0734 - acc: 0.7294 - val_loss: 1.0279 - val_acc: 0.7427\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.9895 - acc: 0.7466\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.74359 to 0.74664, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 662s 662ms/step - loss: 1.0703 - acc: 0.7334 - val_loss: 0.9895 - val_acc: 0.7466\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 1.0247 - acc: 0.7475\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.74664 to 0.74750, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 664s 664ms/step - loss: 1.0633 - acc: 0.7345 - val_loss: 1.0247 - val_acc: 0.7475\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.9922 - acc: 0.7516\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.74750 to 0.75156, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 662s 662ms/step - loss: 1.0667 - acc: 0.7334 - val_loss: 0.9922 - val_acc: 0.7516\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.9972 - acc: 0.7521\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.75156 to 0.75211, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 665s 665ms/step - loss: 1.0610 - acc: 0.7337 - val_loss: 0.9972 - val_acc: 0.7521\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 1.0043 - acc: 0.7431\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.75211\n",
            "1000/1000 [==============================] - 629s 629ms/step - loss: 1.0484 - acc: 0.7387 - val_loss: 1.0043 - val_acc: 0.7431\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.9660 - acc: 0.7550\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.75211 to 0.75500, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 665s 665ms/step - loss: 1.0494 - acc: 0.7366 - val_loss: 0.9660 - val_acc: 0.7550\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 1.0183 - acc: 0.7473\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 630s 630ms/step - loss: 1.0519 - acc: 0.7362 - val_loss: 1.0183 - val_acc: 0.7473\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.9849 - acc: 0.7507\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 633s 633ms/step - loss: 1.0503 - acc: 0.7351 - val_loss: 0.9849 - val_acc: 0.7507\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.9920 - acc: 0.7546\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 631s 631ms/step - loss: 1.0347 - acc: 0.7390 - val_loss: 0.9920 - val_acc: 0.7546\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 1.0198 - acc: 0.7473\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 628s 628ms/step - loss: 1.0501 - acc: 0.7371 - val_loss: 1.0198 - val_acc: 0.7473\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.9921 - acc: 0.7485\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 633s 633ms/step - loss: 1.0318 - acc: 0.7404 - val_loss: 0.9921 - val_acc: 0.7485\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.9726 - acc: 0.7534\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 634s 634ms/step - loss: 1.0422 - acc: 0.7400 - val_loss: 0.9726 - val_acc: 0.7534\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 1.0002 - acc: 0.7545\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 631s 631ms/step - loss: 1.0393 - acc: 0.7392 - val_loss: 1.0002 - val_acc: 0.7545\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.9585 - acc: 0.7544\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 629s 629ms/step - loss: 1.0287 - acc: 0.7414 - val_loss: 0.9585 - val_acc: 0.7544\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 1.0065 - acc: 0.7502\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.75500\n",
            "1000/1000 [==============================] - 631s 631ms/step - loss: 1.0412 - acc: 0.7401 - val_loss: 1.0065 - val_acc: 0.7502\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.9695 - acc: 0.7571\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.75500 to 0.75711, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 667s 667ms/step - loss: 1.0335 - acc: 0.7411 - val_loss: 0.9695 - val_acc: 0.7571\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.9622 - acc: 0.7611\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.75711 to 0.76109, saving model to gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/Stroke_DenseNet/best_model_densenet.ckpt\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1000/1000 [==============================] - 666s 666ms/step - loss: 1.0347 - acc: 0.7409 - val_loss: 0.9622 - val_acc: 0.7611\n",
            "finish training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XdYVEf78PHv0EFQURF7w14AO4oN\nK3ZBUUkUMcYS0zR5En3jk2L6o0lsscYWjRQ1drBGLBiMHcWoUYwRrCiCIqCUef8A/GGkLOwuCzif\n69pL98w5Mzege3NmzswIKSWKoiiKkhcjQwegKIqiFH8qWSiKoij5UslCURRFyZdKFoqiKEq+VLJQ\nFEVR8qWShaIoipIvlSwURVGUfKlkoSiKouRLJQtFURQlXyaGDkBXKlWqJOvUqVPo6x8/fkyZMmV0\nF5COqfi0o+LTjopPO8U5vpMnT96TUtrle6KUslS8WrduLbUREhKi1fX6puLTjopPOyo+7RTn+IAT\nUoPPWNUNpSiKouRLJQtFURQlXypZKIqiKPkqNQPciqKUXikpKURHR5OcnJxjebly5bhw4UIRR6W5\n4hCfhYUFNWrUwNTUtFDXq2ShKEqxFx0djY2NDXXq1EEI8UL5o0ePsLGxMUBkmjF0fFJK7t+/T3R0\nNHXr1i1UHaobSlGUYi85OZmKFSvmmCiU/AkhqFixYq53ZppQyUJRlBJBJQrtaPv9e+mTRWxSLDMP\nzOTvx38bOhRFUZRi66VPFgBfh35N0K0gQ4ehKEoxFRcXx6JFiwp1bb9+/YiLi9P4/M8++4zvvvuu\nUG3p00ufLCpYVmBwo8Hsu7uPp2lPDR2OoijFUF7JIjU1Nc9rg4ODKV++vD7CKlIvfbIAGOs8lviU\neIL+UncXiqK8aPr06URGRuLs7MwHH3zAgQMH6Ny5M4MGDaJp06YADBkyhNatW9OsWTOWLVv27No6\ndepw//59rl27RpMmTRg/fjzNmjWjd+/eJCUl5dnumTNncHFxwdHREQ8PDx48eADA/Pnzadq0KY6O\njowcORKAgwcP4uzsjLOzMy1btuTRo0c6/R6oR2eBXg69qGhWkdXhq/Fo4mHocBRFycOUXVM4c/vM\nc8fS0tIwNjYudJ3OVZyZ6z431/Jvv/2WiIgIzpzJaPfAgQOcOnWKiIiIZ4+irly5kgoVKpCUlETb\ntm0ZOnQoFStWfK6ey5cv4+/vz08//cTw4cP59ddfGTVqVK7t+vj4sGDBArp27conn3zCzJkzmTt3\nLt9++y1///035ubmz7q4vvvuOxYuXIirqysJCQlYWFgU+vuRE3VnAZgYmdDLvhdBfwVxJ+GOocNR\nFKUEaNeu3XNzFubPn4+TkxMuLi5ERUVx+fLlF66pW7cuzs7OALRu3Zpr167lWn98fDxxcXF07doV\ngDFjxnDo0CEAHB0defXVV/nll18wMcn4nd/V1ZX33nuP+fPnExcX9+y4rqg7i0x97PsQEBWA3zk/\npnaYauhwFEXJRU53AIaY9JZ9yfEDBw6wb98+wsLCsLKyolu3bjnOaTA3N3/2d2Nj43y7oXITFBTE\noUOH2L59O1999RXnzp1j+vTp9O/fn+DgYFxdXdm9ezeNGzcuVP05UXcWmeqUqUO76u1YdWYVGav2\nKoqiZLCxsclzDCA+Ph5bW1usrKy4ePEiR48e1brNcuXKYWtry+HDhwFYu3YtXbt2JT09naioKNzc\n3Pjf//5HfHw8CQkJREZG0qJFC6ZNm0bbtm25ePGi1jFkp5JFNr5Ovpy7e47Tt08bOhRFUYqRihUr\n4urqSvPmzfnggw9eKHd3dyc1NZUmTZowffp0XFxcdNLuzz//zAcffICjoyNnzpzhk08+IS0tjVGj\nRtGiRQtatmzJO++8Q/ny5Zk7dy7NmzfH0dERU1NT+vbtq5MYsqhuqGxGNh/J1N1TWX1mNa2qtjJ0\nOIqiFCN+fn7Pve/Wrduzv5ubm7Nz584cr7t27dqzbrKIiIhnx//zn//keP5nn3327O/Ozs453qWE\nhoa+cGzBggV5ha81vd1ZCCFWCiHuCiEicilvLIQIE0I8EUL8519l7kKIS0KIK0KI6fqK8d9sLW0Z\n0ngI686t40nqk6JqVlEUpdjTZzfUasA9j/JY4B3guamKQghjYCHQF2gKeAshmuopxhf4OvsSmxRL\n0GU150JRFCWL3pKFlPIQGQkht/K7UsrjQMq/itoBV6SUV6WUT4EAYLC+4vy3XvV6Uc2mGqvPrC6q\nJhVFUYq94jhmUR2IyvY+Gmif04lCiAnABAB7e3sOHDhQ6EYTEhKeXd+1fFcC/wpk055NVDCrUOg6\ndSl7fMWRik87Kr68lStXLs+nkdLS0nQ+Y1mXikt8ycnJhf45FsdkoTEp5TJgGUCbNm1k9gGngjpw\n4MCzAasqzavgv9Cfv63/xrOjpw4i1V72+IojFZ92VHx5u3DhQp7zKAy9uVB+ikt8FhYWtGzZslDX\nFsdHZ28ANbO9r5F5rMg0rtQYlxourA5freZcKIqiUDyTxXGggRCirhDCDBgJbCvqIHydfIm4G8Gp\nW6eKumlFUUoBa2vrAh0v7vT56Kw/EAY0EkJECyHGCSEmCSEmZZZXEUJEA+8B/808p6yUMhV4C9gN\nXADWSynP6yvO3IxoPgJzY3M10K0oioJ+n4byllJWlVKaSilrSClXSCmXSCmXZJbfzjxeVkpZPvPv\nDzPLgqWUDaWUDlLKr/QVY17KW5THo4kHfhF+as6Forzkpk+fzsKFC5+9z9qgKCEhgR49etCqVSta\ntGjB1q1bNa5TSskHH3xA8+bNadGiBYGBgQDcunWLLl264OzsTPPmzTl8+DBpaWn4+vo+O3fOnDk6\n/xrzU6IHuPXN18mXgIgAtv+1nWFNhxk6HEVRgClTpjxbKjyL1kuUOzszd27uS5SPGDGCKVOm8Oab\nbwKwfv16du/ejYWFBZs3b6Zs2bLcu3cPFxcXBg0apNF+15s2beLMmTOEh4dz79492rZtS5cuXfDz\n86NPnz7MmDGDtLQ0EhMTOXPmDDdu3Hg2A7wgO+/pSnEcsyg2etbrSXWb6qorSlFeci1btuTu3bvc\nvHmT8PBwbG1tqVmzJlJKPvroIxwdHenZsyc3btzgzh3NtjkIDQ3F29sbY2Nj7O3t6dq1K8ePH6dt\n27asWrWKzz77jHPnzmFjY0O9evW4evUqb7/9Nrt27aJs2bJ6/opfpO4s8mBsZIyPkw+zjszi1qNb\nVLWpauiQFOWll9MdQFE8murl5cXGjRu5ffs2I0aMAGDdunXExMRw8uRJTE1NqVOnTo5LkxdEly5d\nOHToEEFBQfj6+vLee+/h4+NDeHg4u3fvZsmSJaxfv56VK1fq4svSmLqzyMcYpzGkyTTWnVtn6FAU\nRTGgESNGEBAQwMaNG/Hy8gIyliavXLkypqamhISE8M8//2hcX+fOnQkMDCQtLY2YmBgOHTpEu3bt\n+Oeff7C3t2f8+PG8/vrrnDp1inv37pGens7QoUP58ssvOXWq6J/SVHcW+WhUqREdanRg9ZnVvN/h\nfY36IhVFKX2aNWvGo0ePqF69OlWrZvQyvPrqqwwcOJAWLVrQpk2bAm025OHhQVhYGE5OTgghmDVr\nFlWqVOHnn39m9uzZmJqaYm1tzZo1a7hx4wZjx44lPT0dgG+++UYvX2NeVLLQgK+zLxN3TOTEzRO0\nrd7W0OEoimIg586de+59pUqVCAsLy/HchISEPI8LIZg9ezazZ89+rnzMmDGMGTPmhesMcTeRneqG\n0sCIZiOwMLFQA92Kory0VLLQQDmLcng28cQ/wp/kVO0GrxRFUUoilSw05Ovky4PkB2y/tN3QoSjK\nS0mt06Ydbb9/KlloqHvd7tQoW4PV4asNHYqivHQsLCy4f/++ShiFJKXk/v37WFhYFLoONcCtIWMj\nY3wcffj2yLfcfHSTajbVDB2Sorw0atSoQXR0NDExMTmWJycna/VBqG/FIT4LCwtq1KhR6OtVsiiA\nMc5j+Dr0a345+wsfun5o6HAU5aVhampK3bp1cy0/cOBAofdpKArFPT5NqG6oAmhYsSEda3Zk9Rm1\nz4WiKC8XlSwKaKzzWC7cu8Dxm8cNHYqiKEqRUcmigLyaemFpYqnmXCiK8lJRyaKA1JwLRVFeRipZ\nFIKvsy9xyXFsvaj5RieKoiglmT63VV0phLgrhIjIpVwIIeYLIa4IIc4KIVplK5slhDgvhLiQeU6x\nWr3PrY4bNcvWVHMuFEV5aejzzmI14J5HeV+gQeZrArAYQAjREXAFHIHmQFugqx7jLLCsfS72RO7h\nxsMbhg5HURRF7/S5B/chIDaPUwYDa2SGo0B5IURVQAIWgBlgDpgCmm09VYR8nX1Jl+n8cvYXQ4ei\nKIqid4Ycs6gORGV7Hw1Ul1KGASHArczXbinlBQPEl6f6FerTqVYnVp1ZpeZcKIpS6gl9ftAJIeoA\nO6SUzXMo2wF8K6UMzXz/GzANiAPmASMyT90LfCilPJxDHRPI6MLC3t6+dUBAQKFjTUhIwNraukDX\nBN0K4ru/vmNhy4U0Ldu00G1rojDxFSUVn3ZUfNpR8RWem5vbSSllm3xPlFLq7QXUASJyKVsKeGd7\nfwmoCnwAfJzt+CdkJIs822rdurXURkhISIGviU+Ol5ZfWsqJ2ydq1bYmChNfUVLxaUfFpx0VX+EB\nJ6QGn+eG7IbaBvhkPhXlAsRLKW8B14GuQggTIYQpGYPbxa4bCqCseVmGNh1KQEQASSlJhg5HURRF\nb/T56Kw/EAY0EkJECyHGCSEmCSEmZZ4SDFwFrgA/AZMzj28EIoFzQDgQLqUstptI+Dr5Ev8knsEB\ng1l0fBF/3f9LjWEoilLq6G3VWSmldz7lEngzh+NpwER9xaVrbnXdmOY6jYCIAN4MzvhyapWrRc+6\nPelZryc96vWgcpnKBo5SURRFO2qJci0ZCSO+7fkt3/T4hsgHkey7uo+9V/ey6eImVp5ZCYCTvRM9\n6/WkV71edK7dGStTKwNHrSiKUjAqWeiIEIL6FepTv0J9JrWZRFp6GidvnXyWPBYcW8D3Yd9jZmyG\na01XetbLuPNoXbU1xkbGhg5fURQlTypZ6ImxkTHtqrejXfV2fNT5Ix4/fUzo9VD2Xt3Lvqv7mLF/\nBjP2z6C8RXm61+1Oj7o96F63O40qNqKYrW6iKIqikkVRKWNWhj71+9Cnfh8A7iTcYf/f+/+v2+rC\nJgCqWlfFra4b3et0p3vd7tS1zX13MEVRlKKikoWB2Fvb493CG+8W3kgpiXwQScjfIey/lpFA/M75\nAVC7XG261+1O1eSqNHjYgOplqxs4ckVRXkYqWRQD2cc7xrcej5SSP2P+JORaCPv/3s+Wi1t4kPyA\nry9+TcOKDZ/ddXSr0w27MnaGDl9RlJeAShbFkBCCZpWb0axyM95q9xZp6WmsDFrJw4oP2X9tP7+c\n+4UlJ5cA4GjviFsdNya0nkBTO/0uOaIoystLbX5UAhgbGdPApgHvd3yfoFeCiP0wlrBxYXzV/Svs\nrOxYenIpjosdeTv4be4n3jd0uIqilEIqWZRApsamuNRw4aPOH7HPZx9RU6OY2Hoii04sosGCBsz/\nYz4paSmGDlNRlFJEJYtSoJJVJRb2X0j4pHBaV2vNu7vexWmJE7uu7DJ0aIqilBIqWZQizSs3Z8+o\nPWwduZWU9BT6rutLv3X9uHjvoqFDUxSlhFPJopQRQjCo0SDOTz7Pd72+40jUEVosbsGUXVN4kPRA\np239/eBvlpxYwiu/vkJAVADxyfE6rV9RlOJDPQ1VSpkZm/F+x/cZ7TSaT0I+YcGxBaw9u5bPu33O\nxDYTMTEq+I8+4WkCIX+HsCdyD7sjd3M59jIAdlZ2xCTG4D/Xn0mtJzHFZQpVbarq+ktSFMWA1J1F\nKVe5TGWWDFjC6YmncbJ34q2db+G0xIk9kXvyvTZdpnPq1im+OfwNbj+7UeF/FRgUMIiVZ1bSoGID\n5rnP48KbF7jznzssabWEvvX78l3Yd9SZV4fXt73OpXuXiuArVBSlKKg7i5eEo70jv/n8xpaLW/jP\n3v/Q55c+DGg4gO97f0/Dig2fnXc74TZ7I/eyO3I3e6/u5e7ju0DGyrlTXabSp34fXGu6Ym5i/lz9\njWwaMXHgRL6K/Yofwn5g5ZmVrDy9ksGNB/Nhxw/pULNDkX69iqLolkoWLxEhBB5NPOjXoB/z/pjH\nl4e+pNmiZrzZ9k3Mjc3ZHbmb8DvhQEbXUm+H3vRx6EMvh15Usa6iURsOFRxY2H8hn3b7lB+P/ciP\nx35ky8UtdK7VmQ9dP6Rfg34YCXVDqygljUoWLyFzE3M+dP2QMU5jmLF/BvP/mI+JkQmutVz5psc3\n9HHog1MVJ60+1CuXqcznbp/zoeuHrDi1gu/Dvmeg/0Ca2TXjg44f4N3CGzNjMx1+VYqi6JM+t1Vd\nKYS4K4SIyKVcCCHmCyGuCCHOCiFaZSurJYTYI4S4IIT4UwhRR19xvszsre1ZPmg50e9FEzstlpAx\nIUzvNJ2WVVvq7Ld/azNr3nV5l8h3IlnrsRYjYYTvVl8c5jvwQ9gPPHrySCftKIqiX/rsD1gNuOdR\n3hdokPmaACzOVrYGmC2lbAK0A+7qKUYFqGZTDWsza722YWpsyijHUYRPCif4lWDqV6jP+3vep9bc\nWsz4bYbOH+tVFEW39JYspJSHgNg8ThkMrJEZjgLlhRBVhRBNARMp5d7MehKklIn6ilMpWkII+jbo\nS8iYEI6OO0qPuj34JvQbuv3cjdikvP65KIpiSIYcaawORGV7H515rCEQJ4TYJIQ4LYSYLYRQ+46W\nQu1rtGfj8I3sGrWLi/cu0nttbzWxT1GKKSGl1F/lGWMNO6SUzXMo2wF8K6UMzXz/GzANqAOsAFoC\n14FAIFhKuSKHOiaQ0YWFvb1964CAgELHmpCQgLW1frtitFHa4wu7H8bH5z+msU1jZrWYhZWJlQ6j\nK/3fP31T8WmnOMfn5uZ2UkrZJt8TpZR6e5HxwR+RS9lSwDvb+0tAVcAFOJjt+GhgYX5ttW7dWmoj\nJCREq+v17WWIb+P5jdJ4prHsuqqrfPz0sfZBZfMyfP/0ScWnneIcH3BCavB5bshuqG2AT+ZTUS5A\nvJTyFnCcjPGLrC3gugN/GipIpegMbTqUNR5rOPTPITwCPUhOTTZ0SIqiZNLbPAshhD/QDagkhIgG\nPgVMAaSUS4BgoB9wBUgExmaWpQkh/gP8JoQQwEngJ33FqRQvr7R4heTUZMZtG8fwDcPZOHyjmo+h\nKMWA3pKFlNI7n3IJvJlL2V7AUR9xKcXfay1fIzk1mTeD3+TVTa/iP9S/UAsfKoqiO+p/oFIsTW47\nmeTUZN7f8z7mxub8PORnjI3UQ3GKYigqWSjF1nsd3iM5NZkZ+2dgYWLBsoHL1LpSimIgKlkoxdpH\nnT8iKSWJLw9/iYWJBQv6LiBjKEtRlKKkkoVS7H3u9jlJqUl8H/Y9liaWzOo1SyUMRSliKlkoxZ4Q\ngtm9ZpOcmsx3Yd9haWrJ526fGzospJRci7vGqVunMDU2xcHWgXq29bA0tTR0aIqicypZKCWCEIL5\nfefzJPUJXxz6AgsTCz7q/FGRxnA74TbHbxzn+M3M143j3E+6/8J51Wyq4WDrgEMFh4w/M/9ev0J9\nKlhWKNKYFUVXVLJQSgwjYcSSAUtISk1ixv4ZWJpYMrXDVL20FZccx4mbJ55LDtEPo5/F0cyuGYMb\nDaZt9ba0qdaGdJlOZGwkkQ8yXldir7D7ym5uJdx6rt7yFuVzTCQp6Sl6+To0IaVU3XpKvlSyUEoU\nYyNjVg9ZzZO0J7y35z0sTCx4o+0bha5PSsmjp484e+fss8Rw4uYJLsdefnZO/Qr16VyrM22rtaVt\n9ba0rNKSMmZlXqirXfV2LxxLTEnk6oOr/5dIMv88desUmy5sIjU9FQDncs4c63oMU2PTQn8thfHo\nySN6re2FcxVnlgxYUqRtKyWLShZKiWNiZIKfpx9PUp8wOXgy5ibmvNbytWflj58+5u7ju8QkxmT8\n+TiGo9ePsmPPjheO3318lydpT55dW6NsDdpWa8tY57G0rd6W1lVbY2tpW+hYrUytaF65Oc0rv7CW\nJqnpqUTFR7H10lam7p7K9H3T+b7P94Vuq6CklIzdOpY/bvzBHzf+wL2+O0MaDymy9pWSRSULpUQy\nNTZlvdd6BgcM5vVtr7Po+CLuJd7j7uO7JKUm5XiNZZQllctUpnKZylSxroKjvSN2VnbYWdnRuFJj\n2lZvq/Fe47pgYmRCXdu6THGZwqGIQ/xw9AfaVm/LyOYji6T9/x35H79e+JVvenxD4PlAJu2YROda\nnaloVbFI2ldKFpUslBLLwsSCzSM2887Od7jx6AbNKjfDzsqOymUq/9+fZTL+vHDyAn179DV0yLl6\no94b3DW6y7ht43K9E9GlPZF7mLF/BiObj2Sa6zT61u9Lm5/a8PbOt/Eb6qfXtpWSSSULpUSzMrVi\n+aDl+Z53zfia/oPRgqmRKRu8NtBqWSs8Az05Nv4Y5S3K66Wtvx/8zciNI2lm14zlA5cjhMCpihMf\nd/mYTw98ildTLzyaeOilbaXkUmsnKEoxUdWmKhu8NvB33N/4bPYhXabrvI3ElEQ8Aj2QSDaP2Pzc\nQP3/6/T/aFmlJZOCJnEv8Z7O21ZKNpUsFKUY6VSrEz/0/oHtf23n68Nf67RuKSUTtk/g7J2z+Hn6\n4VDB4blyU2NTVg9ZzYOkB7y9822dtq2UfC99snj06BGLFi0iKioq/5MVpQi81e4tRjmO4pOQT9h5\neafO6p3/x3zWnVvH526f07dBzuM3jvaOfNzlYwIiAth0YZPO2lZKvpc+WSQnJ/POO++wa9cuQ4ei\nKEDGbPWlA5biaO/Iq5te5eqDq1rXefDaQd7f8z6DGw3Od+b79E7TaVmlJW8EvaG6o5RnXvpkYWdn\nR8+ePQkJCcna81tRDM7K1Ipfh/+KRDJ0/VASUxILXVf0w2iGbxxO/Qr1WeOxJt9l3rN3R70V/Fah\n21VKF70lCyHESiHEXSFERC7lQggxXwhxRQhxVgjR6l/lZYUQ0UKIH/UVYxZvb29u3brFH3/8oe+m\nFEVjDhUc8PP0I/x2OJN2TCrULzNPUp88SzabR2ymrHlZja7L6o4KPB/Ir3/+WuB2NZUu01l4bCHT\n900n+HIw8cnxemtL0Y4+7yxWA+55lPcFGmS+JgCL/1X+BXBIL5H9i4eHB6ampvj7+xdFc4qisb4N\n+vJZt89Ye3Yti44vKvD1bwW/xbEbx1gzZA1N7JoU6NrpnabTqmorJgdPJj5F9x/iSSlJvPLrK7y1\n8y1m/z6b/n79qTCrAq2XtWbqrqlsvrC5RHSD3Um4w52EO4YOQ+/0liyklIeA2DxOGQyskRmOAuWF\nEFUBhBCtAXtgj77iy65s2bJ06NCBwMBAUlNTi6JJRdHYf7v8lwENBzBl9xSOXD+i8XXLTi5j+enl\nzOg8o1DzJkyNTVk9OKM7at7leQW+Pi93Eu7QfU131p9fz6yes3g4/SG/+fzGfzv/l7LmZVlycgme\n6z2xm21H80XNmRw0mcCIQG49upV/5UXoQswFHJc4Um9+PX4I++HZWl+lkSHHLKoD2R9BigaqCyGM\ngO+B/xRlMN27d+fOnTscOHCgKJtVlHwZCSPWeqyldrnaeG3w0ugD82j0Ud4Kfgv3+u7M7Daz0G23\nsG/BJ10/ISQmRGfdURF3I2i/vD3ht8P5dfivfOD6AWXMytC9bndmus0kZEwIcdPiODz2MF91/4rq\nZauzJnwNI38dSbUfqtFwQUNe3/Y6a8LX8E/cPzqJqTAu3btE9zXdEQi61O7C+3vep/3y9py6dcpg\nMemT0OegrhCiDrBDSvnC2gVCiB3At1LK0Mz3vwHTABfASko5SwjhC7SRUuY4yiaEmEBGFxb29vat\nAwICCh3r/fv38fHxoWvXrnz44YeFrkdfEhISsLa2NnQYuVLxaUeT+K4mXOXN02/SwLoBPzj9gIlR\nzgswxD6NZeLJiZgZmbGk1RJsTG20ii01PZVJJydxP+U+q9qsorxZ4WeWH4s9xsw/Z2JpbMlXzb+i\nkU0jja5Lk2lcfnSZ8Phwzsaf5Wz8WRJSEwCwN7enV8VejK0/tsj2aL+RdIMpZ6aQKlOZ4zSH2la1\nORBzgAVXFhCfEs/QGkMZW2cslsYZG2EV539/bm5uJ6WUbfI9UUqZ7wt4FygLCGAFcArorcF1dYCI\nXMqWAt7Z3l8CqgLrgOvANeAe8JCMpJJnW61bt5baCAkJkWPGjJHlypWTycnJWtWlDyEhIYYOIU8q\nPu1oGp/fWT/JZ8h3gt/Jsfxp6lPZeWVnafWVlQy/Ha6z+FZsXyFNPzeVwzcML3Qdi44tksYzjaXT\nYid5Pe66VvGkpafJM7fOyPlH58s+a/tIPkOO3DhSJqUkaVWvJiJjI2WNH2rISrMqyXN3zj1XFpsY\nKydsmyD5DFl7Tm0Z9FeQlLJ4//sDTkgN8oCmafg1KeVDoDdgC4wGvtXw2txsA3wyn4pyAeKllLek\nlK9KKWtJKeuQ0RW1Rko5Xcu2NOLt7U18fDw7d+puIpSi6JJ3C2+mtJ/C/GPzWXd23Qvl7+95n8PX\nD7Ni0Aoc7R111m4963p82vVT1p9fz8Y/Nxbo2rT0NKbsmsLk4Mm413fn8NjD1CxXU6t4jIQRTlWc\neLv92+x8dSfj644nICKAnmt66nVQ/FrcNdx+diMxJZF9o/e9sOCjraUtSwcu5fDYw1iZWtHfrz8j\nN44k9mlew7clg6bJImsbrX7AWinl+WzHcr5ACH8gDGiU+QjsOCHEJCHEpMxTgoGrwBXgJ2BygaPX\nsR49emBnZ6eeilKKtVm9ZtGldhfGbx9P+O3wZ8fXhq9lwbEFvOfynl6WOZ/WaRqtq7ZmctBkYh7H\naHTNoyePGBI4hHl/zGNK+ylsHbkVG3PtusX+TQjBK7VeIXBYICdunsBluQt/3f9Lp20AXI+/jtvP\nbjx88pC9o/fiVMUp13M71erE6Ymn+bzb52y+uJkxx8ew/NRyvaz3VVQ0TRYnhRB7yEgWu4UQNkCe\nX7WU0ltKWVVKaSqlrCGlXCHFpPXdAAAgAElEQVSlXCKlXJJZLqWUb0opHaSULaSUJ3KoY7XMZbxC\nH0xMTPDy8mL79u0kJCQUVbOKUiCmxqYEDgvE1tIWz/WePEh6wKlbp5iwYwJuddz4X6//6aVdEyMT\nVg9ZTfyTeN4MfjPf86Pio+i8qjM7L+9kUb9FzHGfg7GRsV5iAxjebDj7x+wn/kk8HVZ04PA/h3VW\nd/TDaLr/3J0HSQ/YO3ovraq2yvcacxNzPu76MWcnncWhjAPjt4+n2+puXIi5oLO4ipKmyWIcMB1o\nK6VMBEyBsXqLyoBeeeUVkpKS2Lp1q6FDUZRcVbGuwkavjUTFRzFi4wg8Az2xs7IjcFhgrgPfutC8\ncnM+7fopG/7cwIbzG3I97+TNk7Rf3p6/4/4m6JUgrba+LYiONTtydNxR7Kzs6Lm2Z45ddQV189FN\nuv/cnbuP77J71G7aVMt/LDi7RpUaMcdpDisGrSDibgTOS5357MBnPEl9kv/FxYimyaIDcElKGSeE\nGAX8FyiVUy07dOhArVq1VFeUUux1qNmBee7z2Ht1L7cTbrNpxCbsytjpvd0PXT+kTbU2TA6ezN3H\nd18o33xhM51XdcbM2IzfX/udPvX76D2m7BwqOPD7uN/pUKMDozaP4vODnxd6KZ/bCbfpsaYHtxJu\nsWvULtrXaF+oeoQQvNbyNS6+dZFhTYcx8+BMnJc6c+gfzeYdp6SlEP0wmmM3jrHl4hYWHV/Ex/s/\nZtzWcfRd15eJ2ycWKq6C0PRXkMWAkxDCCXgfWA6sAbrqKzBDMTIyYuTIkfzwww/cv3+fihXVFpNK\n8TWpzSQSUxJpVKlRgX/jLSwTIxNWD15Nq2WteCv4LdZ7rQcynqz87vfvmLZvGu1rtGfLiC3YW9sX\nSUz/VsGyAntG72H89vF8euBTIh9E8tPAnzAzNtO4jruP79JjTQ+ux19n16u76Fizo9ZxVS5TmXWe\n6xjtOJo3gt6g6+quvN7ydca3Hs/dx3e5+ehmjq+7j+8ieT7hGQkjqlhXoZpNNRxsHXJpUXc0TRap\nUkophBgM/CilXCGEGKfPwAzJ29ubWbNmsXHjRiZO1H/GVpTCEkLwfsf3i7zdZpWb8VnXz/ho/0ds\nOL+BIY2HMDloMstPL2dEsxGsGrwKS1PLIo8rOzNjM1YPXo2DrQOfHviU6/HX2TR8E7aWtvleey/x\nHj3X9OTvB38T/GownWt31mls7vXdiXgjgpkHZ/JD2A8sP/1/uz0KBJXLVKaaTTWq2VSjTbU2z/6e\n/WVnZafXMaB/0zRZPBJC/D8yHpntnDnL2lR/YRmWk5MTTZo0wd/fXyULRcnFB64fsPniZiYHT2bx\nicWEXAvhv53/y0y3mUU2OS4/Qgg+6foJ9WzrMW7bODqs6EDwq8HUs62X6zWxSbH0XNOTy7GX2eG9\ng251uukltjJmZZjVaxZjncdy6f6lZ0nAvow9psbF7+NV05/oCOAJGfMtbgM1gNl6i8rAhBB4e3tz\n6NAhoqOjDR2OohRLJkYmrBq8iodPHhJ6PZSfh/zMF92/KDaJIrtRjqPYO3ovMYkxtF/enrCosBzP\ne5D0gF5re3Hx3kW2jtxKj3o99B5bE7smDGk8hHbV21GjbI1imShAw2SRmSDWAeWEEAOAZCnlGr1G\nZmDe3t5IKQkMDDR0KIpSbDWr3Izdo3Zz9PWj+Dj5GDqcPHWp3YWwcWGUtyiP289uLzzNFZ8cT59f\n+hBxN4JNIzbR26G3gSItnjRKFkKI4cAxwAsYDvwhhBimz8AMrX79+rRp00Y9FaUo+ehWp5tG8w6K\ng4YVGxI2Low21dowfONw/hf6P6SUPHzyEPd17py5fYaNXhvp16CfoUMtdjQds5hBxhyLuwBCCDtg\nH1Cwef8lzCuvvMJ7773H5cuXadCggaHDURRFBypZVWKfzz7Gbh3L9N+mczn2MhfvXeTEzROsH7ae\ngY0GGjrEYknTzkWjrESR6X4Bri2xRowYgRBC3V0oSiljYWLBOs91/Lfzf1lxegVHo4/iP9S/UPt+\nvCw0/cDfJYTYLYTwzVw2PIiMtZ1KtWrVqtG1a1f8/Pz0tj/3o0eP6N+/P/v379dL/Yqi5MxIGPFF\n9y/YMmILO1/dybCmpbpnXWsadUNJKT8QQgwFXDMPLZNSbtZfWMWHt7c3EydO5MyZM7Rs2VLn9U+b\nNo3g4GDMzMzo3r27zutXFCVvgxsPNnQIJYLGXUlSyl+llO9lvl6KRAEwdOhQTExM9NIVdeDAARYv\nXky5cuXYvXs3iYmJOm9DURRFF/JMFkKIR0KIhzm8HgkhHhZVkIZUsWJF3N3dCQgIID1dd8sLP378\nmHHjxuHg4MAvv/xCUlISu3fv1ln9iqIoupRnspBS2kgpy+bwspFSli2qIA3N29ubqKgojhw5orM6\nP/74Y65evcqKFStwd3enQoUKbNq0SWf1a0pKyRdffEF4eHj+JyuK8tIq9U806cKgQYOwtLTUWVfU\n77//zty5c5k8eTJdu3bFxMSEQYMGsWPHDp4+faqTNjR1+vRpPvnkEz7++OMibVdRlJJFJQsNWFtb\nM2jQIDZs2EBKSopWdSUnJ/Paa69Rs2ZNvv32/3am9fDwIC4ujgMHDmgZbcFkJcDg4GDu3LlTpG0r\nilJyqGShoVdeeYV79+7x22+/aVXPzJkzuXTpEj/99BM2Nv+3vWSvXr0oU6YMmzcX3bMD6enpBAYG\n0rx5c9LS0li3TvuNYhRFKZ30liyEECuFEHeFEBG5lAshxHwhxBUhxFkhRKvM485CiDAhxPnM4yP0\nFWNB9OnTh/Lly+Pn51foOk6cOMHs2bMZN24cvXs/v+6MpaUlffv2ZcuWLTodSM/L77//TlRUFNOn\nT8fFxYVVq1bpbT6Joiglmz7vLFYD7nmU9wUaZL4mkLHBEkAi4COlbJZ5/VwhRHk9xqkRc3Nzhg4d\nyubNm0lKSirw9U+fPuW1117D3t6e7777LsdzPDw8uH37NkePHtU2XI34+/tjYWHBoEGD8PX1JSIi\nglOnThVJ24qilCx6SxZSykNAbB6nDAbWyAxHgfJCiKpSyr+klJcz67gJ3AX0v1ekBry9vUlISCAo\nKKjA13799decO3eOpUuXUr58zrmvf//+mJqaFklXVGpqKhs2bGDgwIHY2NgwYsQIzM3NWb16td7b\nVoqXW7duER9fKndJVnRIfzu75686EJXtfXTmsVtZB4QQ7QAzIDKnCoQQE8i4K8He3l6rweGEhASN\nrq9QoQLz58+nUqVKGtcdGRnJl19+Sc+ePbG2ts6znZYtW+Ln50e/fv0QQhQ4Pk0dP36cmJgYWrRo\n8axeV1dX1qxZw8CBAzEz03z7SX3Ep2sqvpw9ffqUV199FQcHh+ceuPg39f3TTnGPTyNSSr29gDpA\nRC5lO4BO2d7/BrTJ9r4qcAlw0aSt1q1bS22EhIRodN67774rzc3NZVxcnEbnp6SkyFatWsnKlSvL\ne/fu5Xv+0qVLJSDDw8MLFZ+mfH19ZdmyZWVSUtKzY7t375aA3LBhQ4Hr03V8uqbP+KKiouSjR4+0\nqsNQ3781a9ZIQALy/PnzuZ73Mv98daE4xweckBp8xhryaagbQM1s72tkHkMIUZaMxQpnyIwuqmLD\n29ubJ0+eaNxVNHv2bE6dOsWiRYuoWLFivucPHjwYIYReu6KSk5PZtGkTHh4eWFhYPDveo0cPqlev\nrrqiCiA9PZ22bdvy1ltvGTqUApNSMmfOHBwcHLCwsGDu3LmGDkkpxgyZLLYBPplPRbkA8VLKW0II\nM2AzGeMZxW6/jHbt2lGvXj2NJuhduHCBzz77jGHDhjF06FCN6re3t8fV1VWvs7l37tzJw4cP8fb2\nfu64sbExPj4+7Nq1i1u3buVytZLdhQsXuH37Nhs2bODRo0eGDqdADh8+zOnTp/nwww8ZPXo0a9eu\n5d69e4YOSymm9PnorD8QBjQSQkQLIcYJISYJISZlnhIMXAWuAD8BkzOPDwe6AL5CiDOZL2d9xVlQ\nWftz//bbb9y9ezfX89LS0njttdewsbHhxx9/LFAbHh4enD17lqtXr2obbo4CAgKws7OjR48X9xf2\n9fUlLS2NX375RS9tlzahoaEAJCYmGmS5Fm3MnTuXihUrMnr0aKZMmUJycjJLliwxdFhKMaXPp6G8\npZRVpZSmUsoaUsoVUsolUsolmeVSSvmmlNJBStlCSnki8/gvmdc4Z3ud0VecheHt7U1aWhobNmzI\n9Zz58+dz9OhR5s+fj729fYHq9/DI2IBFH11RCQkJbN++HS8vL0xMXny+oWHDhnTs2JHVq1erORca\nCA0Nxd7envr167NmTcnZlv7q1ats2bKFiRMnYmlpSdOmTenduzcLFy4s8iVnlJJBzeAuhGbNmtGi\nRYtcJ+hduXKFGTNmMHDgwBe6ejRRt25dnJ2d9fKb6tatW0lKSmLkyJG5nuPr68uff/7JiRMndN5+\naRMaGkqnTp0YPXo0ISEhREVF5X9RMbBgwQKMjY2ZPHnys2NTp07l9u3bBAYGGjAypbhSyaKQvL29\n+f333/nnn3+eO56ens64ceMwMzNj8eLFzz3+WhCenp6EhYXpfOzA39+fGjVq4Orqmus5w4cPx8LC\nQg105+PGjRtcu3aNTp06MWrUKKSUJWLJlIcPH7JixQqGDx9O9erVnx3v06cPTZo0Yc6cOequUnmB\nShaFlPWbeUBAwHPHlyxZwqFDh5gzZ85z/xELysPDAyklW7du1SrO7GJjY9m9ezcjR47EyCj3H325\ncuXw9PTEz8+P5ORknbVf2mQtWd+pUyfq1atHp06dWLNmTbH/oF21ahWPHj1i6tSpzx0XQjBlyhRO\nnz7NoUOHDBSdUlypZFFIdevWpUOHDs89FXXt2jU+/PBDevfuja+vr1b1N2vWjPr16+t03OLXX38l\nNTVVo66xsWPHEhcXx7Zt23TWfmkTGhqKlZUVTk5OAPj4+HDhwoVivWRKWloa8+fPx9XVlTZt2rxQ\nPnr0aCpWrMicOXMMEJ1SnKlkoQVvb2/Cw8P5888/kVIyYcIEhBAsW7as0N1PWYQQeHp6sn//fuLi\n4nQSr7+/Pw0bNtRoL3E3Nzdq1qypuqLyEBoaiouLC6ampgB4eXlhbm5erAe6t2/fztWrV5kyZUqO\n5ZaWlkyaNIlt27Zx5cqVIo5OKc5UstDC8OHDMTIywt/fn5UrV7J3715mzZpF7dq1dVK/h4cHqamp\n7NixQ+u6bt68yYEDBxg5cqRGiSxrzsXu3bu5efOm1u2XNg8fPiQ8PJxOnTo9O1a+fHkGDRqEv7+/\n1vue6MvcuXOpXbs2Q4YMyfWcyZMnY2JiwoIFC4owMqW4U8lCC/b29vTo0YOff/6Z9957j27dujFx\n4kSd1d+uXTuqVaumk66oDRs2IKUs0NNZY8aMIT09nbVr12rdfmlz9OhR0tPTn0sWkNEVFRMTUyz3\nUz99+jQHDx7k7bffzvGx6SzVqlVjxIgRrFy5Ui0wqDyjkoWWsvbnTklJYfny5XkOHBeUkZERQ4YM\nYefOnVoPNPv7++Ps7Ezjxo01vqZBgwZ06tRJzbnIQWhoKEZGRri4uDx3vE+fPtjZ2RXLrqi5c+dS\npkwZxo0bl++5U6dOJSEhgeXLlxdBZEpJoJKFljw9PalWrRrff/89Dg4OOq/fw8ODpKQkreY8XL16\nlT/++KNQcz58fX25ePEix44dK3T7pdGRI0dwdnZ+brdDAFNTU7y9vdm2bZvOxpp04fbt2/j7+zN2\n7Nhcl8jPrlWrVnTp0oX58+eTmppaBBEqxZ1KFloqV64c0dHRvPHGG3qpv2vXrtja2nL48OFC15H1\neO+IEQXfdNDLywtLS0s10J1NSkoKR48efaELKouPjw9PnjzJc4Z/UVu8eDGpqam88847Gl8zdepU\nrl+/XqRb/SrFl0oWOqDtk095MTU1ZeDAgfz++++FHjQNCAigY8eOhRp4L1u2LEOHDsXf379QOwSW\nRmfOnCExMTHXiY2tWrWiadOmxaYrKjk5mcWLFzNgwAAaNGig8XUDBw6kXr166jFaBVDJokTw9PQk\nISGBgwcPFvja8+fPc+7cuUJ1QWXx9fUlPj5epxMES7KsxQNzSxZCCEaPHk1oaCiRkTnu21Wk/Pz8\niImJyfVx2dwYGxvzzjvvEBYWxp9//qmn6Eq+pUuXsmzZMkOHoXcqWZQAvXv3xsLColBrRfn7+2Nk\nZISXl1eh23dzc6NWrVqqKypTaGgodevWzXOG/quvvooQwuCr90opmTt3Lo6Ojri5uRX4+tdee42y\nZcvy66+/6iG6kk9Kyaeffsr06dOL7ePSuqKSRQlgaWlJ27Zt2bJlC+np6RpfJ6XE39+f7t27F3jl\n2+yMjIwYM2YMe/fu5caNG4WupzSQUj5bPDAvNWvWpHv37qxdu9agT5KFhIRw7tw5pkyZUqjuUhsb\nG15//XUOHDhQYhZJLEoXLlzgzp07PHjwgP379xs6HL1SyaKE6Ny5M7du3SrQU0knTpzg6tWrWnVB\nZcmac1Fc+uGzHDlyhD59+hTZYHJkZCR3797NN1lAxtIZkZGRhIWFFUFkOZszZw52dnZa/Rt4++23\nAQq8L8vLICtBmJmZsXFjsdurTadUsighOnTogImJSYG6ovz9/TEzM8PT01Pr9h0cHOjcuXOxmXMR\nFRXFK6+8QqdOndizZw/ff/99kbSbNV6hSbLw9PTEysrKYAn28uXL7NixgzfeeOO57XMLqk6dOnTu\n3Jlly5aRkJCgwwhLvpCQEGrXrs3QoUPZvHlzqe6KUsmihLC2tqZHjx5s3rxZow/rtLQ0AgMD6du3\nr0bP1Wti7Nix/PXXXxw9arht0RMTE5k5cyaNGjVi8+bNfPzxx8yYMYM//viD6OhovbcfGhqKra2t\nRpMbbWxs8PT0JDAwkCdPnug9tn+bP38+ZmZmOnmse9iwYcTFxfHzzz/rILLSIT09nQMHDuDm5oaX\nlxf3798v1EMoJYU+t1VdKYS4K4SIyKVcCCHmCyGuCCHOCiFaZSsbI4S4nPkao68YSxoPDw+uXLlC\nRESO39LnHD58mJs3b+qkCyrLsGHDsLKyMshAt5SSwMBAGjduzGeffcbAgQO5ePEin3/+OaNGjQJg\ny5Yteo8jNDQUV1dXjWfqjx49mri4OJ2s71UQcXFxrFq1Cm9vb6pUqaJ1fc2aNaNt27bMmzevQONm\npdm5c+eIjY3Fzc0Nd3d3ypQpU6zm1uiaPu8sVgPueZT3BRpkviYAiwGEEBWAT4H2QDvgUyGErR7j\nLDEGDx6MEEKjSVIBAQFYWVkxYMAAnbVvY2PDsGHDCAgIIDExUWf15ufkyZN06dKFkSNHUrFiRQ4e\nPEhgYOCzeSONGzemSZMmep88FhMTw6VLlzTqgsrSo0cPqlatWuRdUcuXL+fx48e8++67OqlPCMHU\nqVO5fPkywcHBOqmzpAsJCQEynha0tLRkwIABbN68udTOeNfnHtyHgNg8ThkMrMnci/soUF4IURXo\nA+yVUsZKKR8Ae8k76bw0qlSpQseOHfP9UExJSWHjxo0MHjyYMmXK6DQGX19fHj58WCS/xd+5c4fX\nX3+dtm3bcunSJZYtW8aJEyfo0qXLC+d6enpy8OBB7t27p7d4sm92pCljY2NGjRpFcHCwXmPLLjU1\nlQULFtC1a1eNlqPX1LBhw6hRo0axm6S3Z88ezp8/X+TthoSE4ODgQM2aNYGM1Q5iYmJK7cZRuS89\nqX/VgezP4kVnHsvt+AuEEBPIuCvB3t6eAwcOFDqYhIQEra7Xt6z4HB0dWbx4Mf7+/lStWjXHc48e\nPcr9+/dp3ry5zr8mKSVVqlRhzpw5VKtW7YX4dOHp06ds2rSJtWvX8vTpU7y8vBg9ejTW1ta5LntS\nq1Yt0tLSmD17Nn379n2hXBfxBQQEYGpqyuPHjwtUV+PGjUlNTeWLL77Aw8Mjx3N0+f07ePAg169f\nZ/z48TqrMyEhgSNHjtCvXz+WLVvG8uXLqV+/vk7q1sbjx48ZPnw4lStXplmzZkXWblpaGr/99hvd\nunV79j0uU6YMFhYWzJs374VuyuL++aIRKaXeXkAdICKXsh1Ap2zvfwPaAP8B/pvt+MfAf/Jrq3Xr\n1lIbISEhWl2vb1nxRUZGSkB+//33uZ47atQoWb58efnkyRO9xPLpp59KIYS8fv36C/FpIz09XW7b\ntk3Wr19fAnLAgAHy0qVLGl9bu3ZtOWDAgBzLdRGfi4uL7NSpU6GudXZ2lm3bts21XJf//jp27Cjr\n1asnU1NTdVZnVnyxsbHSyspK+vr66qxubcyZM0cCEpD//PNPkbV7/PhxCUg/P7/njnt5eUl7e/sX\nvvfF+fMFOCE1+Dw35NNQN4Ca2d7XyDyW23EFqFevHk5OTrk+QpuUlMSWLVsYOnQoZmZmeonBx8cH\nKaVO++H//PNP3N3dGTRoECYmJuzcuZPt27fTsGFDja7P2llwz549PHr0SGdxZUlMTOTkyZMF6oLK\nzsfHh+PHj3Px4kUdR/a8Y8eO8fvvv/POO+9gbGys8/ptbW3x9fXFz8+P27dv67z+gkhLS2PevHnU\nq1cPoEjHUrLGK7p16/bc8WHDhnHnzp1nj1iXJoZMFtsAn8ynolyAeCnlLWA30FsIYZs5sN0785iS\nycPDg99//507d+68UBYUFERCQoJOn4L6t3r16tG1a1edzLm4ePEikydPxtHRkWPHjjFv3jzOnj2L\nu3vBh6k8PDx4+vSpXj40jh8/TkpKSq7rQeXH29sbIyMjvW8kNW/ePGxsbBg7dqze2nj33Xd5+vQp\nS5Ys0VsbmtiyZQvXrl1j9uzZVK1alaCgoCJrOyQkhMaNG7/QFdyvXz8sLS1L51NRmtx+FOYF+AO3\ngBQyxh3GAZOASZnlAlgIRALngDbZrn0NuJL5GqtJey9LN5SUUp49e1YCcunSpS+c5+npKatUqaLT\nLoicrFq1SgIyNDT0hfjy8/TpU7l+/Xrp5uYmAWlqairfeOMNGRMTo1VMqampsnLlynLEiBEvlGn7\n8/3yyy8lIO/fv1/oOvr27Str1aol09LSXijTxb+/6OhoaWJiIqdMmaJ1Xf/27/j69+8v7ezsZFJS\nks7b0pSrq6usW7euTE1NlR4eHtLS0lImJibqvd2nT59Ka2tr+cYbb+RYnvV/MPvPuTh/vmDobigp\npbeUsqqU0lRKWUNKuUJKuURKuSSzXEop35RSOkgpW0gpT2S7dqWUsn7ma5W+YiypmjdvjoODwwtd\nUfHx8QQFBTF8+HC9dEFkN2zYMMqUKcOqVZr/eKKiovj444+pVasWw4cP5++//+abb74hOjqaRYsW\nUalSJa1iMjY2ZsiQIQQFBWm9s+C/hYaG0qxZMypUqFDoOnx8fLh+/brenpZZuHAh6enpBdqzorCm\nTp1KTEwMfn5+em8rJ8eOHePIkSO8++67GBsb4+LiQlJSUpEMIp88eZKEhIRcF2b08vLi9u3bz56e\nKy3UDO4SSAiBh4cH+/fvf243tq1bt/LkyRNGjhyp9xisra3x8vJi/fr1PH78ONfz0tPT2bVrF4MH\nD6ZOnTp89dVXtGnThqCgIK5cucL06dOpXLmyzuLKWs593759OqszLS2NsLCwQo9XZBk8eDA2NjZ6\nmXORmJjI0qVLGTx4MHXr1tV5/f/WvXt3HB0dmTt3rkGWf5kzZw5ly5bltddeA8DZ2RkrK6si6YrK\nWg/q3+MVWfr374+5uXmpWytKJYsSytPTk5SUlOf+c/j7+1OnTp0X9oXWF19fXx49epTjvI+YmBhm\nzZpFgwYN6Nu3L0ePHmXatGlcvXqV7du3069fP73c/bi5uVGuXLlCLeeem/PnzxMfH691srC0tMTL\ny4sNGzbofFLjL7/8QmxsbIH3rCgsIQRTpkzh3Llz/Pbbb0XSZpaoqCg2bNjA+PHjn21ra2ZmRo8e\nPQgKCtJ78goJCaFFixbY2dnlWG5jY0Pfvn359ddfS9Vsd5UsSqj27dtTtWrVZx/UMTEx7N27l5Ej\nR+p1577sOnfuTN26dZ8t/yGl5MiRI4waNYoaNWowbdo0atSogb+/P1FRUXz99dfUqVNHrzGZmZkx\nYMAAtm7dqrOZtAVZPDA/Pj4+JCQk6HQjKZm5Z0XLli3p3LmzzurNj7e3N5UrVy7ySXoLFixASvls\nNdws/fv359q1a1y4cEFvbT958oQjR47kuzfIsGHDuHHjhkHXUdM1lSxKKCMjI4YMGcLOnTtJSkpi\n48aNpKWl6fUpqJxi8PX1Zf/+/fj5+eHk5ESnTp3Yvn07EyZMICIigoMHDzJy5Ei9PcabE09PT2Jj\nY3U2NhAaGkr16tULtS3tv3Xu3JlatWrptCtqz549XLhwgalTpxbZLwoAFhYWTJ48meDgYC5dulQk\nbSYkJLBs2TKGDh36ws+jX79+AHrtijp27BhJSUn5JouBAweWumXLVbIowTw8PEhMTGTPnj0EBATQ\ntGlTWrRoUaQxZM25+OmnnzAxMWHZsmXcuHGDBQsWFOmM2uz69OmDpaWlztaKylo8UBcfxEZGRowe\nPZo9e/Zw69Ytreu7efMmn376KVWqVGH48OFa11dQkyZNwszMjFmzZhVJe6tWrSI+Pp733nvvhbKa\nNWvi6Oio12QREhKCEIKuXbvmeV7ZsmXp06cPGzduLDVdUSpZlGDdunWjfPny/Pjjjxw+fLhIu6Cy\n1KlTh6CgIBYuXMjJkycZP3481tbWRRrDv5UpUwZ3d3c2b96s9X/U69evExUVpZMuqCyjR48mPT1d\nqyeJkpOT+eabb2jYsCGnT5/m22+/xdzcXGcxasre3p4333yTlStX6n2Tp6xJeC4uLrmOy/Xv35/Q\n0NDnHvzQpf379+Ps7Iytbf5rm3p5eREVFcXx48f1EktRU8miBDM1NWXgwIHs27cPKWWRdkFl169f\nP5o2bVrkiSovnp6e3BR8gYIAABhZSURBVLhxQ+v/qIVZPDA/jRo1ol27doWaoCelZNOmTTRt2pSP\nPvqI3r178+effzJmjOFW8v/888+pWbMmEyZM0OvmPzt27CAyMjLHu4os/fv3Jy0tjT179ui8/aSk\nJMLCwujevbtG5w8cOBBTU9NSM0FPJYsSLmthujZt2hSLhd2Ki/79+xd4Z8GchIaGYmNjo/PuPR8f\nH8LDwwkPD9f4mrNnz9KjRw+GDh1KmTJl2LdvH5s2bcLBwUGnsRWUtbU1P/74IxEREXrdsfCHH36g\ndu3auS7GCODi4kKFChX00hUVFhbG06dP8x2vyFK+fHl69+7Nxo0bi8XuktpSyaKE69OnDzVr1mTS\npEmGDqVYsbW1pXv37mzatEmr/6ihoaHPtrTVpREjRmBqaqrR3cW9e/eYPHkyLVu2JDw8nIULF3L6\n9Gl69Oih05i0MWjQIDw9PZk5cyaRkZE6r//kyZMcOnSIt99+O8+fhbGxMe7u7uzcuVPnYwUhISEY\nGxsX6ImzYcOG8c8//xTZAwD6pJJFCWdlZcX169cZN26coUMpdjw9PTXeWTAncXFxnDt3TqddUFkq\nVapEv379WLduXa6P+KakpDBv3jwaNGjAsmXLeOutt7h8+TKTJ0/WefLShfnz52NqasrkyZN1/pv0\nnDlzsLa25vXXX8/33P79+xMTE6PzsYKQkBBat25N2bJlNb5m8ODBmJiYlIrtVlWyUEqtguwsmJOw\nsDCklIVePDA/Pj4+3L59O8dJbbt378bR0ZEpU6bQrl07zp49y7x587RabkTfqlevztdff82ePXvw\n9/fXWb03btwgMDCQcePGUa5cuXzPd3d3x8jISKddUY8fP+aPP/7QuAsqi62tLT179uTgwYMlvitK\nJQul1KpSpQqurq6FHrcIDQ3F2NiY9u3b6ziyDP3798fW1va5ORd//fUXAwcOxN3dndTUVLZv386u\nXbto2rSpXmLQtTfeeIN27doxdepUYmPz2ihTcwVd86pChQp06NBBp8kiNDSU1NTUAicLyHgq6tat\nW5w+fVpn8RiCShZKqebh4UF4eDg3bhR8S5QjR47QqlUrnW9Nm8Xc3Jz/3979R0dVXQsc/24SIBGU\nKlQEw0/lV7CRHxUMEJIliiajAmlAK69WfK/getVla2OFpcXKkoUWBBavVrDWKk/78IG/EEJpMIM0\nVqnAi0AIJogVI1RA/BVEMHG/P+4dOoZMZpLJnQnM/qw1K3fuPXfuzsnM7Nxz7j3nhhtu4MUXX+TQ\noUMUFhZyySWX8NprrzF//nx27tzJtdde26quMgsnKSmJxx9/nI8//ph77rkn6tc7evQoS5cuZeLE\niSfnrYiEz+dj27ZtLXIvCzhNUMnJyc1qkpwwYQJt2rQ57a+KsmRhzmiBK2eaOhnNiRMn2Lx5syf9\nFcFuvvlmjh07xtSpU1m4cCE333wzVVVVFBYWxuW+iZZw6aWXctddd/HEE0+EnAY3UsuXL+eTTz7h\n5z//eZP2C9zN3VJzm/j9fkaOHNmsfxw6d+7MsGHDTvuroixZmDNanz59GDp0aJO/tLZt28ZXX33l\nebK4/PLLGT16NOnp6WzZsoUnnniCrl27enrMWLj//vvp1asXM2bM4Pjx4816jW+++YZFixZx2WWX\nNbnfKCMjg7S0tBZpivr888/ZunVrs5qgArKzs9mzZ0+TLpVubSxZmDNefn4+5eXl7N+/P+J9Amci\nXnVuB4gIpaWlLF68mGHDhnl6rFjq0KEDjz32GBUVFcyfP79Zr1FUVERVVVWzxrwSEfLy8iguLm52\nsgr461//Sl1dXVTJIisri6SkpNN6rChLFuaMl5+fD9CkkV5LS0vp16/fGfFffrzk5uYyZcoUHnzw\nQSorK5u8/6JFi0hLS6OgoKBZx/f5fNTU1ETdFOb3+2nXrh2ZmZnNfo1OnTqRk5PDypUrT9umKE+T\nhYhcIyLviMgeEZnZwPZeIvKqiGwXkY0ikha07TciUi4iFSKyRE6nXj7TqgwaNIgePXpEfFVUYKh1\nr88qEsHixYtJSUnhtttua9KXZFlZGSUlJdxxxx20bdu2WcceN24c7du3j7opqqSkhMzMTFJTU6N6\nncmTJ1NZWdns+37izbNkISJJOHNs5wLpwA9FpP71fwuA5aqaAcwB5rn7jgJGAxnAJcBlQOPDPBoT\ngoiQlZWF3++P6HLOyspKDh8+7Hl/RSLo1q0bDz30EH6/v0ljYS1evJgOHTrwk5/8pNnH7tChAzk5\nOVEliyNHjlBWVhbxeFCNmTRp0ml9VZSXZxYjgD2quldVTwArgAn1yqQDJe6yP2i7AilAO6A90Bb4\nyMNYzRkuKyuLuro6XnnllbBlW3KyIwPTp09n1KhR3HXXXRw+fDhs+QMHDvCnP/2JadOmRTS6a2N8\nPh9VVVVUVVU1a/9NmzahqlH1VwScf/75ZGdnn7b9Fl4miwuBD4KeV7vrgr0N5LvLk4CzRaSzqr6B\nkzwOuI/1qurd9FfmjDdgwADS0tIiaooqLS2lS5cu9O/fPwaRnfnatGnDsmXL+Oyzz7j77rvDlv/d\n735HbW0td955Z9TH9vl8QPMnRPL7/aSmpjJixIioYwFnrKiKigrKy8tb5PViKd4DzBQCvxWRW4BN\nwIdAnYhcDAwCAn0YxSKSparf6qkSkenAdHDG1d+4cWOzA6mpqYlqf69ZfNE5evQoI0aMYM2aNaxb\nt67R9ufi4mIGDhwY0/F8Wnv9tUR8U6ZM4amnniIjI4OhQ4c2WOb48eMsWbKEUaNGUV1dTXV1ddTx\n9ezZk2eeeYYhQ4Y0OeY1a9aQnp4e9VwdgfguuOACRIQFCxbEdVj5ZlFVTx5AJs4ZQeD5LGBWI+U7\nAtXu8t3Ar4K2zQZ+2djxhg8frtHw+/1R7e81iy86fr9f/X6/Arpy5cqQ5Q4cOKCALliwIIbRnR71\nF60vv/xS+/btq/3799djx441WGbZsmUK6MaNG1ssvl/84hfatm1b/eKLL5r0mgcPHlRA586d26T9\nGhIc39ixY3Xw4MFRv2ZLAbZoBN/pXjZDvQX0E5E+ItIOuBFYHVxARLqISCCGWcCT7vI+IFtEkkWk\nLU7ntjVDmaiMGTOGLl26NNoU5cVkR8aRmprK0qVLqaysZN68eadsV9WT95uMHTu2xY7r8/n4+uuv\n2bBhQ5P2C5yptETndrDJkydTXl5ORcXp9ZXmWbJQ1VrgdmA9zhf9/6pquYjMEZHr3WI5wDsiUgl0\nBea661cB7wI7cPo13lbV8D2TxjQiOTmZCRMmsGbNmpA3ar3++uukpKSEbCYx0bnqqquYOnUq8+bN\nY/fu3d/atn79eioqKpp1E15jxowZwznnnNPkfgu/30/Hjh0ZPnx4i8UCzn0/InLadXR7ep+Fqhap\nan9VvUhV57rrZqvqand5lar2c8v8h6oed9fXqeoMVR2kqumqGnoeRWOaID8/ny+++KLBYcHB6dwe\nOXIk7dq1i3FkiWPhwoV07NiRGTNmfGuCooULF9KtWzemTJnSosdr27Yt48ePp6ioqEn3evj9frKy\nspp9n0co3bt3Z/To0ZYsjGnNxo0bx9lnn91gU9TRo0fZtm2bNUF57Pzzz2f+/Pls2rSJp556CoCd\nO3dSXFzMHXfc4Umi9vl87N+/n7KysojKHzhwgN27d7fIJbMNKSgoYPv27c26sz1eLFmYhNK+fXt8\nPh8vv/wydXV139q2efNm6urqLFnEwLRp08jKyqKwsJCDBw+yaNEiUlNTmTFjhifHy83NBSK/hDbQ\nX+FVsvjBD34AcFqdXViyMAknPz+fw4cPnzJseWlpKSIS1RhAJjKBey9qamq49dZbefbZZ7nllls8\nmwmwa9euXHbZZREni5KSEjp16uRZ31VaWhqZmZmn1d3clixMwsnNzaV9+/anNEWVlpaSkZER0dSd\nJnqDBg1i1qxZrF27luPHj7fITXiN8fl8bN68mUOHDoUt6/f7yc7OJikpybN4Jk+eTFlZGXv27PHs\nGC3JkoVJOB07duTqq6/mhRdeONnhWVtbyxtvvGGDB8bYrFmzSE9PJz8/nwEDBnh6LJ/Ph6ry5z//\nudFyH3zwAe+++65nTVABp1tTlCULk5Dy8/Oprq5my5YtAOzYsYOamhrrr4ixlJQUtmzZwooVKzw/\n1rBhw+jatWvYpii/3w94118R0LNnT0aOHGnJwpjW7LrrriMpKelkU5QNHhg/qampLX55akPatGlD\nXl4e69evp7a2NmQ5v99P586d+d73vud5TAUFBWzdupW9e/d6fqxoWbIwCem8884jJyfnZFNUaWkp\nPXv2pEePHvEOzXjI5/Px6aef8re//a3B7apKSUkJ2dnZtGnj/ddjYGKn559/3vNjRcuShUlY+fn5\nVFZWsmvXLkpLS+2sIgFcddVVJCcnh2yKeu+999i3b5/nTVABvXv3ZuTIkcyZM4dHHnmEr7/+OibH\nbQ5LFiZhTZw4EXDuHN6/f78liwRwzjnnkJWVFTJZBPorWno8qMasWLGC7OxsCgsLGTJkyMkYWhtL\nFiZhde/enczMTP74xz8C1l+RKHw+H+Xl5bz//vunbPP7/XTt2pVBgwbFLJ7evXuzZs0aVq9ezbFj\nx7jiiiu44YYbIh6ePVYsWZiElp+fj6rSqVMnBg8eHO9wTAyEmhBJVfH7/eTk5LToQIaRuu666ygv\nL+eBBx5g9erVDBw4kIcffpgTJ07EPJaGWLIwCW3SpEkAjBo1KiYdmib+BgwYQN++fU9JFlVVVezf\nvz9m/RUNSU1NZfbs2ezatYsrr7ySmTNnkpGRQXFxcdxiCrBPh0loF110EYWFhdx+++3xDsXEiIjg\n8/koKSnhyy+/PLk+VvdXRKJPnz689NJLFBUVUVdXx/jx4ykoKGDfvn1xi8mShUl48+fPJy8vL95h\nmBjy+Xx89dVX3+pMLikpoXv37vTr1y+OkX1bbm4uO3bs4MEHH6SoqIiBAwcyd+7ckPOxeMmShTEm\n4WRnZ3PWWWedbIpSVTZu3MgVV1wRl/6KxqSkpHDvvfdSUVFBXl4e9913H5dccgnr1q2LaRyWLIwx\nCSclJYUrr7yStWvXoqrs2rWLgwcPtoomqFB69erFqlWrWL9+PUlJSeTl5TFx4kTee++9mBzf02Qh\nIteIyDsiskdEZjawvZeIvCoi20Vko4ikBW3rKSJ/EZEKEdklIr29jNUYk1h8Ph/79u2jvLy8VfVX\nhDN+/Hi2b9/OQw89xIYNG0hPT+eBBx5o0iyAzeFZshCRJOBRIBdIB34oIun1ii0AlqtqBjAHCJ7F\nfTkwX1UHASOAg17FaoxJPIF+qrVr1+L3++nVqxd9+vSJc1SRadeuHffccw+7d+9mwoQJlJeXe958\nluzha48A9qjqXgARWQFMAHYFlUkHAvNr+4GX3LLpQLKqFgOoao2HcRpjElBaWhqXXnopr7zyChUV\nFVx//fXxDqnJ0tLSWLFiRUyGCfGyGepC4IOg59XuumBvA/nu8iTgbBHpDPQHPhWRF0Tk/0Rkvnum\nYowxLcbn8/H6669z5MiRmA7x0dJiMWqvl2cWkSgEfisitwCbgA+BOpy4soChwD7gOeAW4A/BO4vI\ndGA6ONMmBubNbY6ampqo9veaxRcdiy86Z2p83bp1O7mckpLi2e/Y2usvIqrqyQPIBNYHPZ8FzGqk\nfEeg2l2+HHgtaNuPgEcbO97w4cM1Gn6/P6r9vWbxRcfii86ZGl9tba127txZL7744pYNqJ7WXH/A\nFo3gO93LM4u3gH4i0gfnjOFG4KbgAiLSBTiiqt+4yeTJoH2/IyLfVdVDwBXAFg9jNcYkoKSkJJYs\nWUJKSkq8Q2n1PEsWqlorIrcD64Ek4ElVLReROTiZbDWQA8wTEcVphvqpu2+diBQCr4rTxb8V+L1X\nsRpjEtdNN90UvpDxts9CVYuAonrrZgctrwIanIBWnSuhMryMzxhjTGTsDm5jjDFhWbIwxhgTliUL\nY4wxYVmyMMYYE5YlC2OMMWFZsjDGGBOWJQtjjDFhiXo8BnqsiMgh4P0oXqILcLiFwvGCxRcdiy86\nFl90WnN8vVT1u+EKnTHJIloiskVVvx/vOEKx+KJj8UXH4otOa48vEtYMZYwxJixLFsYYY8KyZPEv\nj8c7gDAsvuhYfNGx+KLT2uMLy/osjDHGhGVnFsYYY8JKqGQhIteIyDsiskdEZjawvb2IPOdu3ywi\nvWMYWw8R8YvILhEpF5E7GyiTIyKfiUiZ+5jd0Gt5HOc/RGSHe/xTJqQSxxK3DreLyLAYxjYgqG7K\nRORzEflZvTIxrUMReVJEDorIzqB154lIsYhUuT/PDbHvj90yVSLy4xjGN19Edrt/vxdF5Dsh9m30\nveBhfL8WkQ+D/oZ5IfZt9PPuYXzPBcX2DxEpC7Gv5/XXoiKZTu9MeOBMwPQu0BdoB7wNpNcr85/A\nUnf5RuC5GMbXDRjmLp8NVDYQXw6wJs71+A+gSyPb84B1gOBMj7s5jn/vf+JcQx63OgTGAsOAnUHr\nfgPMdJdnAg83sN95wF7357nu8rkxim88kOwuP9xQfJG8FzyM79dAYQR//0Y/717FV2/7I8DseNVf\nSz4S6cxiBLBHVfeq6glgBTChXpkJwNPu8ipgnDtTn+dU9YCqbnOXvwAqgAtjcewWNgFYro43cabH\n7RaHOMYB76pqNDdqRk1VNwFH6q0Ofp89DUxsYNergWJVPaKqnwDFwDWxiE9V/6Kqte7TN4G0lj5u\npELUXyQi+bxHrbH43O+OKcD/tPRx4yGRksWFwAdBz6s59cv4ZBn3w/IZ0Dkm0QVxm7+GApsb2Jwp\nIm+LyDoRGRzTwBwK/EVEtorI9Aa2R1LPsXAjoT+k8a7Drqp6wF3+J9C1gTKtpR5vxTlTbEi494KX\nbnebyZ4M0YzXGuovC/hIVatCbI9n/TVZIiWL04KIdASeB36mqp/X27wNp1nlUuC/gJdiHR8wRlWH\nAbnAT0VkbBxiaJSItAOuB1Y2sLk11OFJ6rRHtMpLEkXkXqAWeDZEkXi9Fx4DLgKGAAdwmnpaox/S\n+FlFq/8sBUukZPEh0CPoeZq7rsEyIpIMdAI+jkl0zjHb4iSKZ1X1hfrbVfVzVa1xl4uAtiLSJVbx\nucf90P15EHgR53Q/WCT17LVcYJuqflR/Q2uoQ+CjQNOc+/NgA2XiWo8icgtwLTDVTWiniOC94AlV\n/UhV61T1G+D3IY4b7/pLBvKB50KViVf9NVciJYu3gH4i0sf9z/NGYHW9MquBwFUnBUBJqA9KS3Pb\nN/8AVKjqwhBlLgj0oYjICJy/XyyTWQcROTuwjNMRurNesdXAze5VUZcDnwU1ucRKyP/o4l2HruD3\n2Y+Blxsosx4YLyLnus0s4911nhORa4BfAter6pchykTyXvAqvuA+sEkhjhvJ591LVwK7VbW6oY3x\nrL9mi3cPeywfOFfqVOJcJXGvu24OzocCIAWn6WIP8HegbwxjG4PTHLEdKHMfecBtwG1umduBcpwr\nO94ERsW4/vq6x37bjSNQh8ExCvCoW8c7gO/HOMYOOF/+nYLWxa0OcZLWAeBrnHbzf8fpB3sVqAI2\nAOe5Zb8PPBG0763ue3EPMC2G8e3Bae8PvA8DVwh2B4oaey/EKL7/dt9b23ESQLf68bnPT/m8xyI+\nd/1TgfdcUNmY119LPuwObmOMMWElUjOUMcaYZrJkYYwxJixLFsYYY8KyZGGMMSYsSxbGGGPCsmRh\nTCvgjoa7Jt5xGBOKJQtjjDFhWbIwpglE5N9E5O/uHATLRCRJRGpEZJE485C8KiLfdcsOEZE3g+aF\nONddf7GIbHAHM9wmIhe5L99RRFa5c0k8G6sRj42JhCULYyIkIoOAG4DRqjoEqAOm4tw1vkVVBwOv\nAfe7uywH7lHVDJw7jgPrnwUeVWcww1E4dwCDM9Lwz4B0nDt8R3v+SxkToeR4B2DMaWQcMBx4y/2n\nPxVnEMBv+NeAcc8AL4hIJ+A7qvqau/5pYKU7HtCFqvoigKp+BeC+3t/VHUvInV2tN1Dq/a9lTHiW\nLIyJnABPq+qsb60U+VW9cs0dQ+d40HId9vk0rYg1QxkTuVeBAhE5H07Opd0L53NU4Ja5CShV1c+A\nT0Qky13/I+A1dWZBrBaRie5rtBeRs2L6WxjTDPafizERUtVdInIfzuxmbXBGGv0pcBQY4W47iNOv\nAc7w40vdZLAXmOau/xGwTETmuK8xOYa/hjHNYqPOGhMlEalR1Y7xjsMYL1kzlDHGmLDszMIYY0xY\ndmZhjDEmLEsWxhhjwrJkYYwxJixLFsYYY8KyZGGMMSYsSxbGGGPC+n8VJGxjddvb6AAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xf7OWwaTdJEn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "WA_Jeo2AdIvS",
        "colab_type": "code",
        "outputId": "bfcf7837-106c-4f44-cc2d-3c809fcc23ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def top_3_accuracy(X, Y):\n",
        "    return sparse_top_k_categorical_accuracy(X, Y, 3)\n",
        "  \n",
        "def top_5_accuracy(X, Y):\n",
        "    return sparse_top_k_categorical_accuracy(X, Y, 5)\n",
        "  \n",
        "model_E = MODEL\n",
        "model_E.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=tf.train.AdamOptimizer(),\n",
        "              metrics=['accuracy',top_3_accuracy, top_5_accuracy])\n",
        "\n",
        "model_weights_path = CKPT_PATH\n",
        "model_E.load_weights(model_weights_path)\n",
        "print('finish')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hks1cNludS1s",
        "colab_type": "code",
        "outputId": "4f0ba01d-bcc9-4359-d088-d73c2e2205ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "result = model_E.evaluate_generator(\n",
        "    generate_data(valid_data, BATCH_SIZE, False),\n",
        "    steps = EVALUATE_STEPS,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "print('loss:', result[0])\n",
        "print('top1 accuracy:', result[1])\n",
        "print('top3 accuracy:', result[2])\n",
        "print('top3 accuracy:', result[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "850/850 [==============================] - 138s 162ms/step\n",
            "loss: 0.8496719417501898\n",
            "top1 accuracy: 0.7838941168083864\n",
            "top3 accuracy: 0.9139941189569586\n",
            "top3 accuracy: 0.9383294103426092\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}