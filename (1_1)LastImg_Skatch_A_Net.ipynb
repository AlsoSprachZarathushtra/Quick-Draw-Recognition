{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(1-1)LastImg_Skatch-A-Net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlsoSprachZarathushtra/Quick-Draw-Recognition/blob/master/(1_1)LastImg_Skatch_A_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ioxMYD5fIN0l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Connect Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "QfwNChIWH-gL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEMTrWPCLoJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import"
      ]
    },
    {
      "metadata": {
        "id": "KRLlQxXBrXwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import ReLU\n",
        "from tensorflow.keras.layers import Softmax\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.metrics import sparse_top_k_categorical_accuracy\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from ast import literal_eval\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JUvwhYjZIe-M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters  and  Work-Space Paths"
      ]
    },
    {
      "metadata": {
        "id": "dPOH3112IVQN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "BATCH_SIZE = 200\n",
        "EPOCHS = 50\n",
        "STEPS_PER_EPOCH = 850\n",
        "VALIDATION_STEPS = 100\n",
        "EVALUATE_STEPS = 850\n",
        "IMAGE_SIZE = 225\n",
        "LINE_SIZE = 3\n",
        "\n",
        "\n",
        "# load path\n",
        "TRAIN_DATA_PATH = 'gdrive/My Drive/QW/Data/Data_10000/All_classes_10000.csv'\n",
        "VALID_DATA_PATH = 'gdrive/My Drive/QW/Data/My_test_data/My_test_data.csv'\n",
        "LABEL_DICT_PATH = 'gdrive/My Drive/QW/Data/labels_dict.npy'\n",
        "\n",
        "# save path\n",
        "CKPT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(1-1)LastImg_Skatch-A-Net/best_model_1_1(128).ckpt'\n",
        "LOSS_PLOT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(1-1)LastImg_Skatch-A-Net/loss_plot_1_1(128).png'\n",
        "ACC_PLOT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(1-1)LastImg_Skatch-A-Net/acc_plot_1_1(128).png'\n",
        "LOG_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(1-1)LastImg_Skatch-A-Net/Log_1_1(128).log'\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTH2CjZKLbQ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ]
    },
    {
      "metadata": {
        "id": "tjIQVoD0LjKY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_data(data, batch_size, choose_recognized):\n",
        "    data = data.sample(frac = 1)\n",
        "    while 1:\n",
        "        \n",
        "#         get columns' values named 'drawing', 'word' and 'recognized'\n",
        "        drawings = data[\"drawing\"].values\n",
        "        drawing_recognized = data[\"recognized\"].values\n",
        "        drawing_class = data[\"word\"].values\n",
        "      \n",
        "#         initialization\n",
        "        cnt = 0\n",
        "        data_X =[]\n",
        "        data_Y =[]\n",
        "        \n",
        "#         generate batch\n",
        "        for i in range(len(drawings)):\n",
        "            if choose_recognized:\n",
        "                if drawing_recognized[i] == 'False':    #Choose according to recognized value\n",
        "                    continue\n",
        "            draw = drawings[i]\n",
        "            label = drawing_class[i]\n",
        "            stroke_vec = literal_eval(draw)\n",
        "            img = np.zeros([256, 256])\n",
        "            for j in range(len(stroke_vec)): \n",
        "                line = np.array(stroke_vec[j]).T\n",
        "                cv2.polylines(img, [line], False, 1, LINE_SIZE)\n",
        "            img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE), interpolation = cv2.INTER_NEAREST)\n",
        "            img = img[:,:, np.newaxis]\n",
        "            x = img\n",
        "            y = labels2nums_dict[label]\n",
        "            data_X.append(x)\n",
        "            data_Y.append(y)\n",
        "            cnt += 1\n",
        "            if cnt==batch_size:        #generate a batch when cnt reaches batch_size \n",
        "                cnt = 0\n",
        "                yield (np.array(data_X), np.array(data_Y))\n",
        "                data_X = []\n",
        "                data_Y = []\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z3SIDIfoSR2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Callbacks"
      ]
    },
    {
      "metadata": {
        "id": "fhoAdkcESQiM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a class named LossHitory \n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = {'batch':[], 'epoch':[]}\n",
        "        self.accuracy = {'batch':[], 'epoch':[]}\n",
        "        self.val_loss = {'batch':[], 'epoch':[]}\n",
        "        self.val_acc = {'batch':[], 'epoch':[]}\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses['batch'].append(logs.get('loss'))\n",
        "        self.accuracy['batch'].append(logs.get('acc'))\n",
        "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
        "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.losses['epoch'].append(logs.get('loss'))\n",
        "        self.accuracy['epoch'].append(logs.get('acc'))\n",
        "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
        "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
        "\n",
        "    def loss_plot(self, loss_type, loss_fig_save_path, acc_fig_save_path):\n",
        "        iters = range(len(self.losses[loss_type]))\n",
        "        plt.figure('acc')\n",
        "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
        "        plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
        "        plt.grid(True)\n",
        "        plt.xlabel(loss_type)\n",
        "        plt.ylabel('acc')\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        plt.savefig(acc_fig_save_path)\n",
        "        plt.show()\n",
        "        \n",
        "        \n",
        "        plt.figure('loss')\n",
        "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
        "        plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
        "        plt.grid(True)\n",
        "        plt.xlabel(loss_type)\n",
        "        plt.ylabel('loss')\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        plt.savefig(loss_fig_save_path)\n",
        "        plt.show()\n",
        "        \n",
        "# create a object from LossHistory class\n",
        "History = LossHistory()\n",
        "\n",
        "print(\"finish!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUBqEb49S7qZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    CKPT_PATH, \n",
        "    verbose = 1, \n",
        "    monitor='val_acc', \n",
        "    mode = 'max', \n",
        "    save_best_only=True)\n",
        "\n",
        "print(\"finish!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FylkwHH_NHkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3,\n",
        "                      min_delta=0.005, mode='max', cooldown=3, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JxwkrXMIrLO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "csv_logger = CSVLogger(LOG_PATH, separator=',', append=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bwRxaI2QTibU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ]
    },
    {
      "metadata": {
        "id": "aj041zzZTwrF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load train data and valid data\n",
        "#  labels_dict and data path\n",
        "\n",
        "# labels convert into nums\n",
        "labels_dict = np.load(LABEL_DICT_PATH)\n",
        "labels2nums_dict = {v: k for k, v in enumerate(labels_dict)}\n",
        "\n",
        "# read csv \n",
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "valid_data = pd.read_csv(VALID_DATA_PATH)\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_sA1QMzUysO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "-DXg_7LEU1Ap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_input = Input(shape=(IMAGE_SIZE,IMAGE_SIZE,1), name='Input')\n",
        "\n",
        "x = Conv2D(64, (15,15), strides=3, padding='valid',name='Conv2D_1')(x_input)\n",
        "x = ReLU(name='ReLU_1')(x)\n",
        "x = MaxPool2D(pool_size=(3,3),strides=2, name='Pooling_1')(x)\n",
        "\n",
        "x = Conv2D(128, (5,5), strides=1, padding='valid',name='Conv2D_2')(x)\n",
        "x = ReLU(name='ReLU_2')(x)\n",
        "x = MaxPool2D(pool_size=(3,3),strides=2, name='Pooling_2')(x)\n",
        "\n",
        "x = Conv2D(256, (3,3), strides=1, padding='same',name='Conv2D_3')(x)\n",
        "x = ReLU(name='ReLU_3')(x)\n",
        "\n",
        "x = Conv2D(256, (3,3), strides=1, padding='same',name='Conv2D_4')(x)\n",
        "x = ReLU(name='ReLU_4')(x)\n",
        "\n",
        "x = Conv2D(256, (3,3), strides=1, padding='same',name='Conv2D_5')(x)\n",
        "x = ReLU(name='ReLU_5')(x)\n",
        "x = MaxPool2D(pool_size=(3,3),strides=2, name='Pooling_5')(x)\n",
        "\n",
        "x_shape = x.shape[1]\n",
        "x = Conv2D(512, (int(x_shape),int(x_shape)), strides=1, padding='valid',name='Conv2D_FC_6')(x)\n",
        "x = ReLU(name='ReLU_6')(x)\n",
        "x = Dropout(0.5,name='Dropout_6')(x)\n",
        "\n",
        "x = Conv2D(512, (1,1), strides=1, padding='valid',name='Conv2D_FC_7')(x)\n",
        "x = ReLU(name='ReLU_7')(x)\n",
        "x = Dropout(0.5,name='Dropout_7')(x)\n",
        "\n",
        "x = Conv2D(340, (1,1), strides=1, padding='valid',name='Conv2D_FC_8')(x)\n",
        "x = Flatten(name='Flatten')(x)\n",
        "x_output = Softmax(name='Softmax')(x)\n",
        "\n",
        "MODEL = keras.models.Model(inputs=x_input, outputs=x_output)\n",
        "MODEL.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02zm3e7qU87T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Complie"
      ]
    },
    {
      "metadata": {
        "id": "Rtz3F1UAU_RW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MODEL\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.load_weights(CKPT_PATH)\n",
        "print('finish')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOj3QaVNVm-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "5Kl8pgH8Vope",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('start training')\n",
        "# callbacks = [History, cp_callback]\n",
        "\n",
        "history = model.fit_generator(generate_data(train_data, BATCH_SIZE, True),\n",
        "                              steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                              epochs = 53,\n",
        "                              validation_data = generate_data(valid_data, BATCH_SIZE, False) ,\n",
        "                              validation_steps = VALIDATION_STEPS,\n",
        "                              verbose = 1,\n",
        "                              initial_epoch = 50,\n",
        "                              callbacks = [History,cp_callback,ReduceLR,csv_logger]\n",
        "                             )\n",
        "print(\"finish training\")\n",
        "\n",
        "History.loss_plot('epoch', LOSS_PLOT_PATH, ACC_PLOT_PATH)\n",
        "\n",
        "print('finish!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INkEw6CjX87U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "k3GnYp7PX713",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def top_3_accuracy(X, Y):\n",
        "        return sparse_top_k_categorical_accuracy(X, Y, 3)\n",
        "  \n",
        "def top_5_accuracy(X, Y):\n",
        "        return sparse_top_k_categorical_accuracy(X, Y, 5)\n",
        "  \n",
        "model_E = MODEL\n",
        "model_E.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy',top_3_accuracy, top_5_accuracy])\n",
        "\n",
        "model_weights_path = CKPT_PATH  \n",
        "model_E.load_weights(model_weights_path)\n",
        "print('finish')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PyjiI3iYZn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result = model_E.evaluate_generator(\n",
        "    generate_data(valid_data, BATCH_SIZE, False),\n",
        "    steps = EVALUATE_STEPS,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "print('loss:', result[0])\n",
        "print('top1 accuracy:', result[1])\n",
        "print('top3 accuracy:', result[2])\n",
        "print('top3 accuracy:', result[3])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}